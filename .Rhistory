geom_raster(aes(fill=density)) +
geom_contour(colour="white") +
scale_fill_viridis_c() +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_fixed(xlim=c(-1.5,1.5), ylim=c(-1.5,1.5)) +
ggtitle("Reduction of 200-Component GMM via Salmond (1990).")
graphics.off()
ggplot(odf, aes(x=x,y=y,z=density)) +
facet_grid(class ~ .) +
geom_raster(aes(fill=density)) +
geom_contour(colour="white") +
scale_fill_viridis_c() +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_fixed(xlim=c(-1.5,1.5), ylim=c(-1.5,1.5)) +
ggtitle("Reduction of 200-Component GMM via Salmond (1990).")
graphics.off()
ggplot(odf, aes(x=x,y=y,z=density)) +
facet_grid(. ~ class) +
geom_raster(aes(fill=density)) +
geom_contour(colour="white") +
scale_fill_viridis_c() +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_fixed(xlim=c(-1.5,1.5), ylim=c(-1.5,1.5)) +
ggtitle("Reduction of 200-Component GMM via Salmond (1990).")
levels(odf$class) = c("M=1","M=3","M=9")
# visualize
ggplot(odf, aes(x=x,y=y,z=density)) +
facet_grid(. ~ class) +
geom_raster(aes(fill=density)) +
geom_contour(colour="white") +
scale_fill_viridis_c() +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_fixed(xlim=c(-1.5,1.5), ylim=c(-1.5,1.5)) +
ggtitle("Reduction of 200-Component GMM via Salmond (1990).")
library(T4cluster)
help("gmr1990S")
library(T4cluster)
library(T4cluster)
# -------------------------------------------------------------
# Generate 20 datasets with noise and fix GMM
list_gmm  = list()
for (i in 1:20){
data_i = gensmiley(sd=0.25)$data
list_gmm[[i]] = gmm(data_i, k=10)
}
# Find the average of models
gcenter = gcsum(list_gmm)
# Do Reduction for M=1,3,9
gr1 = gmr2007R(gcenter, M=1)
gr3 = gmr2007R(gcenter, M=3)
gr9 = gmr2007R(gcenter, M=9)
# prepare grid and density evaluation
pgrid = as.matrix(expand.grid(x=seq(from=-1.5,to=1.5,length.out=300),
y=seq(from=-1.5,to=1.5,length.out=300)))
prob1 = gmmdensity(pgrid, gr1)
prob3 = gmmdensity(pgrid, gr3)
prob9 = gmmdensity(pgrid, gr9)
# wrap as a single dataframe
obj1 = rbind(cbind(pgrid, prob1), cbind(pgrid, prob3), cbind(pgrid, prob9))
obj2 = as.factor(rep(c(1,3,9),each=90000))
odf  = data.frame(x=obj1[,1], y=obj1[,2], density=obj1[,3], class=obj2)
levels(odf$class) = c("M=1","M=3","M=9")
# visualize
ggplot(odf, aes(x=x,y=y,z=density)) +
facet_grid(. ~ class) +
geom_raster(aes(fill=density)) +
geom_contour(colour="white") +
scale_fill_viridis_c() +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_fixed(xlim=c(-1.5,1.5), ylim=c(-1.5,1.5)) +
ggtitle("Reduction of 200-Component GMM via Runnalls (2007).")
gr1$weight
gr3$weight
gr9$weight
library(T4cluster)
help(gmr2003W)
# Do Reduction for M=1,3,9
gr1 = gmr2003W(gcenter, M=1)
gr3 = gmr2003W(gcenter, M=3)
gr9 = gmr2003W(gcenter, M=9)
pgrid = as.matrix(expand.grid(x=seq(from=-1.5,to=1.5,length.out=300),
y=seq(from=-1.5,to=1.5,length.out=300)))
prob1 = gmmdensity(pgrid, gr1)
prob3 = gmmdensity(pgrid, gr3)
prob9 = gmmdensity(pgrid, gr9)
# wrap as a single dataframe
obj1 = rbind(cbind(pgrid, prob1), cbind(pgrid, prob3), cbind(pgrid, prob9))
obj2 = as.factor(rep(c(1,3,9),each=90000))
odf  = data.frame(x=obj1[,1], y=obj1[,2], density=obj1[,3], class=obj2)
levels(odf$class) = c("M=1","M=3","M=9")
# visualize
ggplot(odf, aes(x=x,y=y,z=density)) +
facet_grid(. ~ class) +
geom_raster(aes(fill=density)) +
geom_contour(colour="white") +
scale_fill_viridis_c() +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_fixed(xlim=c(-1.5,1.5), ylim=c(-1.5,1.5)) +
ggtitle("Reduction of 200-Component GMM via Williams and Maybeck (2003).")
library(T4cluster)
library(T4cluster)
library(T4cluster)
library(T4cluster)
library(T4cluster)
pkgdown::build_site()
library(T4cluster)
library(T4cluster)
library(T4cluster)
pkgdown::build_site()
install.packages(c("MASS","rstiefel"))
install.packages(c("MASS", "rstiefel"))
library(T4cluster)
XX = genLP(n=100, k=5)
library(T4cluster)
XX = genLP(n=100, k=5)
XX$data
dim(XX$data)
library(T4cluster)
## test for visualization
set.seed(10)
tester = gen.LP(n=100, nl=1, np=2, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## visualize
opar <- par(mfrow=c(2,2))
plot(dat2[,1],dat2[,2],pch=19,cex=0.5,col=label,main="PCA")
plot(data[,1],data[,2],pch=19,cex=0.5,col=label,main="Axis 1 vs 2")
plot(data[,1],data[,3],pch=19,cex=0.5,col=label,main="Axis 1 vs 3")
plot(data[,2],data[,3],pch=19,cex=0.5,col=label,main="Axis 2 vs 3")
par(opar)
tester = genLP(n=100, nl=1, np=2, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## visualize
opar <- par(mfrow=c(2,2))
plot(dat2[,1],dat2[,2],pch=19,cex=0.5,col=label,main="PCA")
plot(data[,1],data[,2],pch=19,cex=0.5,col=label,main="Axis 1 vs 2")
plot(data[,1],data[,3],pch=19,cex=0.5,col=label,main="Axis 1 vs 3")
plot(data[,2],data[,3],pch=19,cex=0.5,col=label,main="Axis 2 vs 3")
par(opar)
opar <- par(mfrow=c(2,2), pty="s")
plot(dat2[,1],dat2[,2],pch=19,cex=0.5,col=label,main="PCA")
plot(data[,1],data[,2],pch=19,cex=0.5,col=label,main="Axis 1 vs 2")
plot(data[,1],data[,3],pch=19,cex=0.5,col=label,main="Axis 1 vs 3")
plot(data[,2],data[,3],pch=19,cex=0.5,col=label,main="Axis 2 vs 3")
par(opar)
scatterplot3d::scatterplot3d(x=data, pch=19, cex.symbols=0.5, color=label)
library(T4cluster)
## test for visualization
set.seed(10)
tester = genLP(n=100, nl=1, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## visualize
opar <- par(mfrow=c(2,2), pty="s")
plot(dat2[,1],dat2[,2],pch=19,cex=0.5,col=label,main="PCA")
plot(data[,1],data[,2],pch=19,cex=0.5,col=label,main="Axis 1 vs 2")
plot(data[,1],data[,3],pch=19,cex=0.5,col=label,main="Axis 1 vs 3")
plot(data[,2],data[,3],pch=19,cex=0.5,col=label,main="Axis 2 vs 3")
par(opar)
scatterplot3d::scatterplot3d(x=data, pch=19, cex.symbols=0.5, color=label)
opar <- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(dat2[,1],dat2[,2],pch=19,cex=0.5,col=label,main="PCA")
plot(data[,1],data[,2],pch=19,cex=0.5,col=label,main="Axis 1 vs 2")
plot(data[,1],data[,3],pch=19,cex=0.5,col=label,main="Axis 1 vs 3")
plot(data[,2],data[,3],pch=19,cex=0.5,col=label,main="Axis 2 vs 3")
par(opar)
library(T4cluster)
help(kmeans)
library(T4cluster)
library(T4cluster)
library(T4cluster)
set.seed(10)
tester = genLP(n=100, nl=1, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## run MSM algorithm with K=2, 3, and 4
maxiter = 1000
output2 = msm(data, K=2, iter=maxiter)
library(T4cluster)
output2 = msm(data, K=2, iter=maxiter)
output2[[1]]
## run MSM algorithm with K=2, 3, and 4
maxiter = 1000
output2 = msm(data, K=2, iter=maxiter)
output3 = msm(data, K=3, iter=maxiter)
output4 = msm(data, K=4, iter=maxiter)
## extract final clustering information
nrec  = length(output2)
finc2 = output2[[nrec]]$cluster
finc3 = output3[[nrec]]$cluster
finc4 = output4[[nrec]]$cluster
## visualize
opar <- par(mfrow=c(3,4))
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(2,3)")
par(opar)
output3[[1]]
length(output2)
length(output3)
length(output4)
vec2 = rep(0,50)
vec3 = rep(0,50)
vec4 = rep(0,50)
for (i in 1:50){
vec2[i] = length(unique(output2[[i]]$cluster))
vec3[i] = length(unique(output3[[i]]$cluster))
vec4[i] = length(unique(output4[[i]]$cluster))
}
par(mfrow=c(1,3))
hist(vec2, main="K=2")
hist(vec3, main="K=3")
hist(vec4, main="K=4")
vec2
vec3
vec4
output3[[i]]$cluster
tester$class
tester = genLP(n=100, nl=2, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
maxiter = 5000
output2 = msm(data, K=2, iter=maxiter)
output3 = msm(data, K=3, iter=maxiter)
output4 = msm(data, K=4, iter=maxiter)
n234 = length(output2)
vec2 = rep(0,n234)
vec3 = rep(0,n234)
vec4 = rep(0,n234)
for (i in 1:n234){
vec2[i] = length(unique(output2[[i]]$cluster))
vec3[i] = length(unique(output3[[i]]$cluster))
vec4[i] = length(unique(output4[[i]]$cluster))
}
par(mfrow=c(1,3))
hist(vec2, main="K=2")
hist(vec3, main="K=3")
hist(vec4, main="K=4")
output2[[i]]$cluster
output4[[i]]$cluster
library(T4cluster)
## run MSM algorithm with K=2, 3, and 4
maxiter = 5000
output2 = msm(data, K=2, iter=maxiter)
output3 = msm(data, K=3, iter=maxiter)
output4 = msm(data, K=4, iter=maxiter)
n234 = length(output2)
vec2 = rep(0,n234)
vec3 = rep(0,n234)
vec4 = rep(0,n234)
for (i in 1:n234){
vec2[i] = length(unique(output2[[i]]$cluster))
vec3[i] = length(unique(output3[[i]]$cluster))
vec4[i] = length(unique(output4[[i]]$cluster))
}
par(mfrow=c(1,3))
hist(vec2, main="K=2")
hist(vec3, main="K=3")
hist(vec4, main="K=4")
n234 = length(output2)
vec2 = rep(0,n234)
vec3 = rep(0,n234)
vec4 = rep(0,n234)
for (i in 1:n234){
vec2[i] = length(unique(output2[[i]]$cluster))
vec3[i] = length(unique(output3[[i]]$cluster))
vec4[i] = length(unique(output4[[i]]$cluster))
}
par(mfrow=c(1,3))
hist(vec2, main="K=2")
hist(vec3, main="K=3")
hist(vec4, main="K=4")
maxiter = 5000
output2 = msm(data, k=2, iter=maxiter)
output3 = msm(data, k=3, iter=maxiter)
output4 = msm(data, k=4, iter=maxiter)
n234 = length(output2)
vec2 = rep(0,n234)
vec3 = rep(0,n234)
vec4 = rep(0,n234)
for (i in 1:n234){
vec2[i] = length(unique(output2[[i]]$cluster))
vec3[i] = length(unique(output3[[i]]$cluster))
vec4[i] = length(unique(output4[[i]]$cluster))
}
par(mfrow=c(1,3))
hist(vec2, main="K=2")
hist(vec3, main="K=3")
hist(vec4, main="K=4")
vec2
vec3
vec4
output4[[1]]
output2[[1]]$P
output3[[1]]$P
output4[[1]]$P
x1 = output2[[1]]
x2 = output2[[2]]
xx = c(x1, x2)
xx
class(x)
class(xx)
## extract final clustering information
nrec  = length(output2)
finc2 = output2[[nrec]]$cluster
finc3 = output3[[nrec]]$cluster
finc4 = output4[[nrec]]$cluster
## visualize
opar <- par(mfrow=c(3,4))
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(2,3)")
par(opar)
## generate a toy example
set.seed(10)
tester = genLP(n=100, nl=2, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## run MSM algorithm with k=2, 3, and 4
maxiter = 500
output2 = msm(data, k=2, iter=maxiter)
output3 = msm(data, k=3, iter=maxiter)
output4 = msm(data, k=4, iter=maxiter)
## extract final clustering information
nrec  = length(output2)
finc2 = output2[[nrec]]$cluster
finc3 = output3[[nrec]]$cluster
finc4 = output4[[nrec]]$cluster
## visualize
opar <- par(mfrow=c(3,4))
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(2,3)")
par(opar)
## generate a toy example
set.seed(10)
tester = genLP(n=100, nl=2, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## run MSM algorithm with k=2, 3, and 4
maxiter = 500
output2 = msm(data, k=2, iter=maxiter)
output3 = msm(data, k=3, iter=maxiter)
output4 = msm(data, k=4, iter=maxiter)
## extract final clustering information
nrec  = length(output2)
finc2 = output2[[nrec]]$cluster
finc3 = output3[[nrec]]$cluster
finc4 = output4[[nrec]]$cluster
## visualize
opar <- par(mfrow=c(3,4))
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(2,3)")
par(opar)
## generate a toy example
set.seed(10)
tester = genLP(n=100, nl=2, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## run MSM algorithm with k=2, 3, and 4
maxiter = 500
output2 = msm(data, k=2, iter=maxiter)
output3 = msm(data, k=3, iter=maxiter)
output4 = msm(data, k=4, iter=maxiter)
## extract final clustering information
nrec  = length(output2)
finc2 = output2[[nrec]]$cluster
finc3 = output3[[nrec]]$cluster
finc4 = output4[[nrec]]$cluster
## visualize
opar <- par(mfrow=c(3,4))
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc2+1,main="K=2:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc3+1,main="K=3:Axis(2,3)")
plot(dat2[,1],dat2[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:PCA")
plot(data[,1],data[,2],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,2)")
plot(data[,1],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(1,3)")
plot(data[,2],data[,3],pch=19,cex=0.3,col=finc4+1,main="K=4:Axis(2,3)")
par(opar)
output2[[length(output2)]]
PP = output2[[length(output2)]]$P
PP
P1 = PP[[1]]
t(PP)%*%PP
t(P1)%*%P1
Matrix::rankMatrix(P1)
Matrix::rankMatrix(P2)
Matrix::rankMatrix(PP[[2]])
Matrix::rankMatrix(PP[[3]])
PP
library(T4cluster)
library(T4cluster)
pkgdown::build_site()
library(T4cluster)
library(T4cluster)
install.packages("mlbench")
library(T4cluster)
vector("list",5)
matrix(0,nrow=K,ncol=n)
matrix(0,nrow=3,ncol=2)
array(0,c(3,2))
library(T4cluster)
library(T4cluster)
library(T4cluster)
methods(msm)
methods("predit")
methods("predict")
xx= list(1)
xx
library(T4cluster)
help(predict.msm)
output2
testmsm = output2[[1]]
testmsm
predict.msm(data, testmsm)
testmsm = structure(output2[[1]], class="msm")
predict.msm(data, testmsm)
predict(data, testmsm)
class(testmsm)
rm(list=ls())
library(T4cluster)
set.seed(10)
tester = genLP(n=100, nl=2, np=1, iso.var=0.1)
data   = tester$data
label  = tester$class
## do PCA for data reduction
proj = base::eigen(stats::cov(data))$vectors[,1:2]
dat2 = data%*%proj
## run MSM algorithm with k=2, 3, and 4
maxiter = 500
output2 = msm(data, k=2, iter=maxiter)
iter1 = output2[[1]]
class(iter12)
class(iter1)
label_pred = predict(data, iter1)
library(T4cluster)
label_pred = predict(iter1, data)
label_pred
label_mcmc = iter1$cluster
label_pred - label_mcmc
pkgdown::build_site()
